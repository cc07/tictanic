{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Training using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import debug as tf_debug\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('./data/train_processed.csv')\n",
    "X_predict = pd.read_csv('./data/test_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>UnknownAge</th>\n",
       "      <th>Baby</th>\n",
       "      <th>Child</th>\n",
       "      <th>Young</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Alone</th>\n",
       "      <th>Title</th>\n",
       "      <th>TicketGroup</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.273456</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.473882</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.278271</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>189.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323563</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.061874</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.436302</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.207289</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.436302</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.062850</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex       Age  SibSp  Parch      Fare  Cabin  Embarked  UnknownAge  \\\n",
       "0       3    1  0.273456      1      0  0.056604      7         0           0   \n",
       "1       1    0  0.473882      1      0  0.278271      2         1           0   \n",
       "2       3    0  0.323563      0      0  0.061874      7         0           0   \n",
       "3       1    0  0.436302      1      0  0.207289      2         0           0   \n",
       "4       3    1  0.436302      0      0  0.062850      7         0           0   \n",
       "\n",
       "   Baby  Child  Young  FamilySize  Alone  Title  TicketGroup  Survived  \n",
       "0     0      0      1           2      0      2          0.0         0  \n",
       "1     0      0      0           2      0      1        189.0         1  \n",
       "2     0      0      1           1      1      1          0.0         1  \n",
       "3     0      0      0           2      0      1         19.0         1  \n",
       "4     0      0      0           1      1      2          0.0         0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>UnknownAge</th>\n",
       "      <th>Baby</th>\n",
       "      <th>Child</th>\n",
       "      <th>Young</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Alone</th>\n",
       "      <th>Title</th>\n",
       "      <th>TicketGroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.430039</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.061126</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.586622</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.054652</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.774521</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.075635</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.336089</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.067632</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.273456</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.047967</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex       Age  SibSp  Parch      Fare  Cabin  Embarked  UnknownAge  \\\n",
       "0       3    1  0.430039      0      0  0.061126      7         2           0   \n",
       "1       3    0  0.586622      1      0  0.054652      7         0           0   \n",
       "2       2    1  0.774521      0      0  0.075635      7         2           0   \n",
       "3       3    1  0.336089      0      0  0.067632      7         0           0   \n",
       "4       3    0  0.273456      1      1  0.047967      7         0           0   \n",
       "\n",
       "   Baby  Child  Young  FamilySize  Alone  Title  TicketGroup  \n",
       "0     0      0      0           1      1      2          0.0  \n",
       "1     0      0      0           2      0      1          0.0  \n",
       "2     0      0      0           1      1      2          0.0  \n",
       "3     0      0      1           1      1      2          0.0  \n",
       "4     0      0      1           3      0      1        107.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_predict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into 3 sets: train, test and valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = X_train['Survived']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train.drop('Survived', axis=1), y_train, test_size=0.2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (569, 16) (569,)\n",
      "Validation set (179, 16) (179,)\n",
      "Test set (143, 16) (143,)\n"
     ]
    }
   ],
   "source": [
    "print('Training set', X_train.shape, y_train.shape)\n",
    "print('Validation set', X_valid.shape, y_valid.shape)\n",
    "print('Test set', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reformat(X, y):\n",
    "    #X = X.reshape((-1, -1)).astype(np.float32)\n",
    "    y = (np.arange(1) == y[:,None]).astype(np.float32)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = reformat(X_train, y_train)\n",
    "X_valid, y_valid = reformat(X_valid, y_valid)\n",
    "X_test, y_test = reformat(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (569, 16) (569, 1)\n",
      "Validation set (179, 16) (179, 1)\n",
      "Test set (143, 16) (143, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Training set', X_train.shape, y_train.shape)\n",
    "print('Validation set', X_valid.shape, y_valid.shape)\n",
    "print('Test set', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  correct_pred = tf.equal(tf.round(predictions), labels)\n",
    "  return tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "_startLearningRate = 0.05\n",
    "_learningDecayRate = 0.98\n",
    "_decaySteps = 1000\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    hidden_units = 10\n",
    "    is_training = tf.Variable(True, dtype=tf.bool)\n",
    "#     learning_rate = tf.placeholder(tf.float32)\n",
    "\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(None, X_train.shape[1]))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(None, y_train.shape[1]))\n",
    "    tf_valid_dataset = tf.cast(tf.constant(X_valid.values), tf.float32)\n",
    "    #tf_test_dataset = tf.cast(tf.constant(X_test.values), tf.float32)\n",
    "    \n",
    "    initializer = tf.contrib.layers.xavier_initializer()\n",
    "    fc = tf.layers.dense(tf_train_dataset, hidden_units, activation=None, kernel_initializer=initializer)\n",
    "    fc = tf.layers.batch_normalization(fc, training=is_training)\n",
    "    fc = tf.nn.relu(fc)\n",
    "    \n",
    "    logits = tf.layers.dense(fc, 1, activation=None)    \n",
    "\n",
    "    #weights = tf.Variable(tf.truncated_normal([X_train.shape[1], y_train.shape[1]]))\n",
    "#     weights = tf.Variable(tf.truncated_normal([X_train.shape[1], 200]))\n",
    "#     biases = tf.Variable(tf.zeros([200]))\n",
    "#     biases = tf.Variable(tf.constant(0.1, shape=[200]))\n",
    "    \n",
    "    #weights1 = tf.Variable(tf.truncated_normal([y_train.shape[1], y_train.shape[1]]))\n",
    "#     weights1 = tf.Variable(tf.truncated_normal([200, y_train.shape[1]]))\n",
    "#     biases1 = tf.Variable(tf.zeros([y_train.shape[1]]))\n",
    "#     biases1 = tf.Variable(tf.constant(0.1, shape=[y_train.shape[1]]))\n",
    "\n",
    "    #logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "#     hidden = tf.nn.relu(tf.matmul(tf_train_dataset, weights) + biases)   \n",
    "#     hidden = tf.nn.dropout(hidden, 0.5)\n",
    "#     logits = tf.nn.relu(tf.matmul(hidden, weights1) + biases1)\n",
    "\n",
    "    #test = tf.reduce_mean(tf.nn.softmax(logits))\n",
    "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "#     loss = tf.reduce_mean(tf.nn.softmax(logits))\n",
    "    global_step = tf.Variable(0)\n",
    "    learning_rate = tf.train.exponential_decay(_startLearningRate, global_step, _decaySteps, _learningDecayRate)\n",
    "    \n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "#     optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "    #train_prediction = tf.nn.softmax(logits)\n",
    "    #valid_prediction = tf.nn.softmax(tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "    #test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)\n",
    "    train_prediction = tf.nn.sigmoid(logits)\n",
    "    #valid_prediction = tf.nn.sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 0.906418\n",
      "Minibatch accuracy: 0.6035\n",
      "Valid accuracy: 0.6313\n",
      "Minibatch loss at step 100: 0.389071\n",
      "Minibatch accuracy: 0.8379\n",
      "Valid accuracy: 0.6313\n",
      "Minibatch loss at step 200: 0.360105\n",
      "Minibatch accuracy: 0.8496\n",
      "Valid accuracy: 0.7430\n",
      "Minibatch loss at step 300: 0.339357\n",
      "Minibatch accuracy: 0.8789\n",
      "Valid accuracy: 0.7374\n",
      "Minibatch loss at step 400: 0.333700\n",
      "Minibatch accuracy: 0.8730\n",
      "Valid accuracy: 0.5978\n",
      "Minibatch loss at step 500: 0.318279\n",
      "Minibatch accuracy: 0.8672\n",
      "Valid accuracy: 0.6257\n",
      "Minibatch loss at step 600: 0.300603\n",
      "Minibatch accuracy: 0.8809\n",
      "Valid accuracy: 0.6425\n",
      "Minibatch loss at step 700: 0.291699\n",
      "Minibatch accuracy: 0.8828\n",
      "Valid accuracy: 0.7542\n",
      "Minibatch loss at step 800: 0.297431\n",
      "Minibatch accuracy: 0.8867\n",
      "Valid accuracy: 0.7654\n",
      "Minibatch loss at step 900: 0.278551\n",
      "Minibatch accuracy: 0.8984\n",
      "Valid accuracy: 0.8268\n",
      "Minibatch loss at step 1000: 0.270693\n",
      "Minibatch accuracy: 0.9062\n",
      "Valid accuracy: 0.8156\n",
      "Minibatch loss at step 1100: 0.262922\n",
      "Minibatch accuracy: 0.8984\n",
      "Valid accuracy: 0.8324\n",
      "Minibatch loss at step 1200: 0.265128\n",
      "Minibatch accuracy: 0.8906\n",
      "Valid accuracy: 0.7765\n",
      "Minibatch loss at step 1300: 0.250908\n",
      "Minibatch accuracy: 0.8984\n",
      "Valid accuracy: 0.7933\n",
      "Minibatch loss at step 1400: 0.243260\n",
      "Minibatch accuracy: 0.8945\n",
      "Valid accuracy: 0.8101\n",
      "Minibatch loss at step 1500: 0.239750\n",
      "Minibatch accuracy: 0.9082\n",
      "Valid accuracy: 0.8268\n",
      "Minibatch loss at step 1600: 0.250195\n",
      "Minibatch accuracy: 0.8984\n",
      "Valid accuracy: 0.8156\n",
      "Minibatch loss at step 1700: 0.238294\n",
      "Minibatch accuracy: 0.9023\n",
      "Valid accuracy: 0.7933\n",
      "Minibatch loss at step 1800: 0.230728\n",
      "Minibatch accuracy: 0.9062\n",
      "Valid accuracy: 0.7877\n",
      "Minibatch loss at step 1900: 0.231481\n",
      "Minibatch accuracy: 0.9082\n",
      "Valid accuracy: 0.8212\n",
      "Minibatch loss at step 2000: 0.237478\n",
      "Minibatch accuracy: 0.9004\n",
      "Valid accuracy: 0.8156\n",
      "Minibatch loss at step 2100: 0.231270\n",
      "Minibatch accuracy: 0.9141\n",
      "Valid accuracy: 0.8045\n",
      "Minibatch loss at step 2200: 0.222961\n",
      "Minibatch accuracy: 0.9043\n",
      "Valid accuracy: 0.7933\n",
      "Minibatch loss at step 2300: 0.221062\n",
      "Minibatch accuracy: 0.9121\n",
      "Valid accuracy: 0.8212\n",
      "Minibatch loss at step 2400: 0.228427\n",
      "Minibatch accuracy: 0.9023\n",
      "Valid accuracy: 0.8101\n",
      "Minibatch loss at step 2500: 0.219797\n",
      "Minibatch accuracy: 0.9102\n",
      "Valid accuracy: 0.7709\n",
      "Minibatch loss at step 2600: 0.214052\n",
      "Minibatch accuracy: 0.9121\n",
      "Valid accuracy: 0.8045\n",
      "Minibatch loss at step 2700: 0.210759\n",
      "Minibatch accuracy: 0.9082\n",
      "Valid accuracy: 0.7877\n",
      "Minibatch loss at step 2800: 0.217518\n",
      "Minibatch accuracy: 0.9043\n",
      "Valid accuracy: 0.8045\n",
      "Minibatch loss at step 2900: 0.215881\n",
      "Minibatch accuracy: 0.9102\n",
      "Valid accuracy: 0.7989\n",
      "Minibatch loss at step 3000: 0.204117\n",
      "Minibatch accuracy: 0.9199\n",
      "Valid accuracy: 0.7989\n",
      "Minibatch loss at step 3100: 0.207863\n",
      "Minibatch accuracy: 0.9141\n",
      "Valid accuracy: 0.8268\n",
      "Minibatch loss at step 3200: 0.211564\n",
      "Minibatch accuracy: 0.9102\n",
      "Valid accuracy: 0.7989\n",
      "Minibatch loss at step 3300: 0.205668\n",
      "Minibatch accuracy: 0.9199\n",
      "Valid accuracy: 0.8212\n",
      "Minibatch loss at step 3400: 0.198594\n",
      "Minibatch accuracy: 0.9219\n",
      "Valid accuracy: 0.7821\n",
      "Minibatch loss at step 3500: 0.199976\n",
      "Minibatch accuracy: 0.9160\n",
      "Valid accuracy: 0.7989\n",
      "Minibatch loss at step 3600: 0.207533\n",
      "Minibatch accuracy: 0.9102\n",
      "Valid accuracy: 0.8268\n",
      "Minibatch loss at step 3700: 0.209856\n",
      "Minibatch accuracy: 0.9180\n",
      "Valid accuracy: 0.7989\n",
      "Minibatch loss at step 3800: 0.194319\n",
      "Minibatch accuracy: 0.9219\n",
      "Valid accuracy: 0.7933\n",
      "Minibatch loss at step 3900: 0.199072\n",
      "Minibatch accuracy: 0.9219\n",
      "Valid accuracy: 0.7933\n",
      "Minibatch loss at step 4000: 0.199743\n",
      "Minibatch accuracy: 0.9141\n",
      "Valid accuracy: 0.8268\n",
      "Minibatch loss at step 4100: 0.205581\n",
      "Minibatch accuracy: 0.9160\n",
      "Valid accuracy: 0.7654\n",
      "Minibatch loss at step 4200: 0.191105\n",
      "Minibatch accuracy: 0.9258\n",
      "Valid accuracy: 0.7821\n",
      "Minibatch loss at step 4300: 0.192122\n",
      "Minibatch accuracy: 0.9199\n",
      "Valid accuracy: 0.8268\n",
      "Minibatch loss at step 4400: 0.190785\n",
      "Minibatch accuracy: 0.9219\n",
      "Valid accuracy: 0.7989\n",
      "Minibatch loss at step 4500: 0.203845\n",
      "Minibatch accuracy: 0.9160\n",
      "Valid accuracy: 0.7877\n",
      "Minibatch loss at step 4600: 0.187315\n",
      "Minibatch accuracy: 0.9219\n",
      "Valid accuracy: 0.7877\n",
      "Minibatch loss at step 4700: 0.190750\n",
      "Minibatch accuracy: 0.9180\n",
      "Valid accuracy: 0.7933\n",
      "Minibatch loss at step 4800: 0.192732\n",
      "Minibatch accuracy: 0.9258\n",
      "Valid accuracy: 0.7709\n",
      "Minibatch loss at step 4900: 0.202564\n",
      "Minibatch accuracy: 0.9238\n",
      "Valid accuracy: 0.7374\n",
      "Minibatch loss at step 5000: 0.187584\n",
      "Minibatch accuracy: 0.9277\n",
      "Valid accuracy: 0.7318\n"
     ]
    }
   ],
   "source": [
    "num_steps = 5001\n",
    "report_interval = 100\n",
    "x_collect = []\n",
    "train_loss_collect = []\n",
    "train_acc_collect = []\n",
    "valid_loss_collect = []\n",
    "valid_acc_collect = []\n",
    "    \n",
    "with tf.Session(graph=graph) as session:\n",
    "    \n",
    "    tf.global_variables_initializer().run()\n",
    "    saver = tf.train.Saver()\n",
    "    #session = tf_debug.LocalCLIDebugWrapperSession(session)\n",
    "    #session.add_tensor_filter(\"has_inf_or_nan\", tf_debug.has_inf_or_nan)\n",
    "    \n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "\n",
    "        offset = (step * batch_size) % (X_train.shape[0] - batch_size)\n",
    "\n",
    "        batch_data = X_train.values[offset:(offset + batch_size), :]\n",
    "        batch_labels = y_train[offset:(offset + batch_size), :]\n",
    "\n",
    "        feed_dict = { \n",
    "            tf_train_dataset: batch_data, \n",
    "            tf_train_labels: batch_labels, \n",
    "            is_training: True,\n",
    "            learning_rate: 0.005\n",
    "        }\n",
    "        \n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "\n",
    "        if (step % report_interval == 0):\n",
    "            x_collect.append(step)\n",
    "            train_loss_collect.append(l)\n",
    "            train_acc_collect.append(accuracy(predictions, batch_labels).eval())\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.4f\" % accuracy(predictions, batch_labels).eval())\n",
    "            #print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), y_valid))\n",
    "            #print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), y_test))\n",
    "            \n",
    "        valid_data = X_valid.values\n",
    "        valid_labels = y_valid\n",
    "        \n",
    "        feed_dict = {\n",
    "            tf_train_dataset: valid_data,\n",
    "            tf_train_labels: valid_labels,\n",
    "            is_training: False,\n",
    "            learning_rate: 0.001\n",
    "        }\n",
    "        \n",
    "        valid_l, valid_predictions = session.run([loss, train_prediction], feed_dict=feed_dict)\n",
    "\n",
    "        if (step % report_interval == 0):\n",
    "            valid_loss_collect.append(valid_l)\n",
    "            valid_acc_collect.append(accuracy(valid_predictions, valid_labels).eval())            \n",
    "            #print(\"Valid loss at step %d: %f\" % (step, valid_l))\n",
    "            print(\"Valid accuracy: %.4f\" % accuracy(valid_predictions, valid_labels).eval())\n",
    "            \n",
    "        feed_dict = {\n",
    "            tf_train_dataset: X_predict.values\n",
    "        }\n",
    "        \n",
    "        predict_result = session.run([train_prediction], feed_dict=feed_dict)        \n",
    "        \n",
    "    saver.save(session, \"./data/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12d14ba58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_collect, train_loss_collect, \"r--\")\n",
    "plt.plot(x_collect, valid_loss_collect, \"g^\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12eb4a358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_collect, train_acc_collect, \"r--\")\n",
    "plt.plot(x_collect, valid_acc_collect, \"g^\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./data/model.ckpt\n",
      "Valid accuracy: 0.8324\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "\n",
    "    tf.global_variables_initializer().run()\n",
    "    saver = tf.train.Saver()        \n",
    "    saver.restore(session, \"./data/model.ckpt\")\n",
    "    \n",
    "    valid_data = X_valid.values\n",
    "    valid_labels = y_valid\n",
    "\n",
    "    feed_dict = {\n",
    "        tf_train_dataset: valid_data,\n",
    "        tf_train_labels: valid_labels,\n",
    "        is_training: False\n",
    "    }\n",
    "\n",
    "    valid_l, valid_predictions = session.run([loss, train_prediction], feed_dict=feed_dict)\n",
    "    print(\"Valid accuracy: %.4f\" % accuracy(valid_predictions, valid_labels).eval())\n",
    "\n",
    "    feed_dict = {\n",
    "        tf_train_dataset: X_predict.values\n",
    "    }\n",
    "\n",
    "    predict_result = session.run([train_prediction], feed_dict=feed_dict)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "binarizer = Binarizer(0.5)\n",
    "\n",
    "test_predict_result = binarizer.fit_transform(predict_result[0])\n",
    "test_predict_result = test_predict_result.astype(np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = test['PassengerId'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r['Survived'] = test_predict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r.to_csv('./data/output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>0.677033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>120.810458</td>\n",
       "      <td>0.468170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>892.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>996.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1204.750000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived\n",
       "count   418.000000  418.000000\n",
       "mean   1100.500000    0.677033\n",
       "std     120.810458    0.468170\n",
       "min     892.000000    0.000000\n",
       "25%     996.250000    0.000000\n",
       "50%    1100.500000    1.000000\n",
       "75%    1204.750000    1.000000\n",
       "max    1309.000000    1.000000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/cc/anaconda/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at step 0 : 0.0160054\n",
      "Minibatch accuracy: 0.6250\n",
      "Valid accuracy: 0.5978\n",
      "Minibatch loss at step 500 : nan\n",
      "Minibatch accuracy: 0.0000\n",
      "Valid accuracy: 0.5978\n",
      "Minibatch loss at step 1000 : nan\n",
      "Minibatch accuracy: 0.0000\n",
      "Valid accuracy: 0.5978\n",
      "Minibatch loss at step 1500 : nan\n",
      "Minibatch accuracy: 0.0000\n",
      "Valid accuracy: 0.5978\n",
      "Minibatch loss at step 2000 : nan\n",
      "Minibatch accuracy: 0.0000\n",
      "Valid accuracy: 0.5978\n",
      "Minibatch loss at step 2500 : nan\n",
      "Minibatch accuracy: 0.0000\n",
      "Valid accuracy: 0.5978\n",
      "Minibatch loss at step 3000 : nan\n",
      "Minibatch accuracy: 0.0000\n",
      "Valid accuracy: 0.5978\n",
      "Minibatch loss at step 3500 : nan\n",
      "Minibatch accuracy: 0.0000\n",
      "Valid accuracy: 0.5978\n",
      "Minibatch loss at step 4000 : nan\n",
      "Minibatch accuracy: 0.0000\n",
      "Valid accuracy: 0.5978\n",
      "Minibatch loss at step 4500 : nan\n",
      "Minibatch accuracy: 0.0000\n",
      "Valid accuracy: 0.5978\n",
      "Minibatch loss at step 5000 : nan\n",
      "Minibatch accuracy: 0.0000\n",
      "Valid accuracy: 0.5978\n",
      "Minibatch loss at step 5500 : nan\n",
      "Minibatch accuracy: 0.0000\n",
      "Valid accuracy: 0.5978\n",
      "Minibatch loss at step 6000 : nan\n",
      "Minibatch accuracy: 0.0000\n",
      "Valid accuracy: 0.5978\n",
      "Minibatch loss at step 6500 : nan\n",
      "Minibatch accuracy: 0.0000\n",
      "Valid accuracy: 0.5978\n",
      "Minibatch loss at step 7000 : nan\n",
      "Minibatch accuracy: 0.0000\n",
      "Valid accuracy: 0.5978\n",
      "Minibatch loss at step 7500 : nan\n",
      "Minibatch accuracy: 0.0000\n",
      "Valid accuracy: 0.5978\n",
      "Minibatch loss at step 8000 : nan\n",
      "Minibatch accuracy: 0.0000\n",
      "Valid accuracy: 0.5978\n",
      "Minibatch loss at step 8500 : nan\n",
      "Minibatch accuracy: 0.0000\n",
      "Valid accuracy: 0.5978\n",
      "Minibatch loss at step 9000 : nan\n",
      "Minibatch accuracy: 0.0000\n",
      "Valid accuracy: 0.5978\n",
      "Minibatch loss at step 9500 : nan\n",
      "Minibatch accuracy: 0.0000\n",
      "Valid accuracy: 0.5978\n",
      "Minibatch loss at step 10000 : nan\n",
      "Minibatch accuracy: 0.0000\n",
      "Valid accuracy: 0.5978\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "_imageSize = X_train.shape[1]\n",
    "_numLabels = y_train.shape[1]\n",
    "_trainSubset = 100\n",
    "_batchSize = 24\n",
    "_hiddenLayers = [2048, 1]\n",
    "_numInputs = _imageSize\n",
    "_startLearningRate = 0.5\n",
    "_learningDecayRate = 0.98\n",
    "_decaySteps = 1000\n",
    "_numSteps = 10001\n",
    "_regularizationRate = 0.00001\n",
    "_dropoutKeepRate = 0.5\n",
    "\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "    correct_pred = tf.equal(tf.round(predictions), labels)\n",
    "    return tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "def validateNumHiddenLayers(numHiddenLayers):\n",
    "    if numHiddenLayers < 1:\n",
    "        raise ValueError('Number of hidden layers must be >= 1')\n",
    "\n",
    "def generateHiddenLayerKey(layerNum):\n",
    "    return 'h' + str(layerNum)\n",
    "\n",
    "def generateHiddenLayer(layerNum, previousLayer, weights, biases, training, dropoutKeepRate):\n",
    "    key = generateHiddenLayerKey(layerNum)\n",
    "    if training:\n",
    "        hiddenLayer = tf.nn.relu(tf.matmul(previousLayer, weights[key]) + biases[key])\n",
    "        hiddenLayer = tf.nn.dropout(hiddenLayer, dropoutKeepRate)\n",
    "        return hiddenLayer\n",
    "    else:\n",
    "        hiddenLayer = tf.nn.relu(tf.matmul(tf.cast(previousLayer, tf.float32), weights[key]) + biases[key])\n",
    "        return hiddenLayer\n",
    "\n",
    "\n",
    "def multilayerNetwork(inputs, weights, biases, numHiddenLayers, training, dropoutKeepRate):\n",
    "    validateNumHiddenLayers(numHiddenLayers)\n",
    "\n",
    "    hiddenLayer = generateHiddenLayer(1, inputs, weights, biases, training, dropoutKeepRate)\n",
    "\n",
    "    for layerNum in range(numHiddenLayers+1):\n",
    "        if layerNum > 1:\n",
    "            hiddenLayer = generateHiddenLayer(layerNum, hiddenLayer, weights, biases, training, dropoutKeepRate)\n",
    "\n",
    "    return tf.matmul(hiddenLayer, weights['out']) + biases['out']\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "    dataset = dataset.reshape((-1, _imageSize * _imageSize)).astype(np.float32)\n",
    "    # Map 2 to [0.0, 1.0, 0.0 ...], 3 to [0.0, 0.0, 1.0 ...]\n",
    "    labels = (np.arange(_numLabels) == labels[:, None]).astype(np.float32)\n",
    "    return dataset, labels\n",
    "\n",
    "#source:  http://arxiv.org/pdf/1502.01852v1.pdf\n",
    "def calculateOptimalWeightStdDev(numPreviousLayerParams):\n",
    "    return math.sqrt(2.0/numPreviousLayerParams)\n",
    "\n",
    "def generateWeights(hiddenLayers, numInputs, numLabels):\n",
    "    numHiddenLayers = hiddenLayers.__len__()\n",
    "    validateNumHiddenLayers(numHiddenLayers)\n",
    "    weights = {}\n",
    "\n",
    "    numHiddenFeatures = hiddenLayers[0]\n",
    "    stddev = calculateOptimalWeightStdDev(numInputs)\n",
    "    weights[generateHiddenLayerKey(1)] = tf.Variable(tf.truncated_normal([numInputs, numHiddenFeatures], 0, stddev))\n",
    "\n",
    "    for layerNum in range(numHiddenLayers+1):\n",
    "        if layerNum > 1:\n",
    "            previousNumHiddenFeatures = numHiddenFeatures\n",
    "            numHiddenFeatures = hiddenLayers[layerNum-1]\n",
    "            stddev = calculateOptimalWeightStdDev(previousNumHiddenFeatures)\n",
    "            weights[generateHiddenLayerKey(layerNum)] = tf.Variable(tf.truncated_normal([previousNumHiddenFeatures, numHiddenFeatures], 0, stddev))\n",
    "\n",
    "    stddev = calculateOptimalWeightStdDev(numHiddenFeatures)\n",
    "    weights['out'] = tf.Variable(tf.truncated_normal([numHiddenFeatures, numLabels], 0, stddev))\n",
    "    return weights\n",
    "\n",
    "def generateBiases(hiddenLayers,  numLabels):\n",
    "    numHiddenLayers = hiddenLayers.__len__()\n",
    "    validateNumHiddenLayers(numHiddenLayers)\n",
    "    biases = {}\n",
    "\n",
    "    numHiddenFeatures = hiddenLayers[0]\n",
    "    biases[generateHiddenLayerKey(1)] = tf.Variable(tf.zeros([numHiddenFeatures]))\n",
    "\n",
    "    for layerNum in range(numHiddenLayers+1):\n",
    "        if layerNum > 1:\n",
    "            numHiddenFeatures = hiddenLayers[layerNum-1]\n",
    "            biases[generateHiddenLayerKey(layerNum)] = tf.Variable(tf.zeros([numHiddenFeatures]))\n",
    "\n",
    "    biases['out'] = tf.Variable(tf.zeros([numLabels]))\n",
    "    return biases\n",
    "\n",
    "def generateRegularizers(weights, biases, numHiddenLayers):\n",
    "    validateNumHiddenLayers(numHiddenLayers)\n",
    "    regularizers = tf.nn.l2_loss(weights['h1']) + tf.nn.l2_loss(biases['h1'])\n",
    "\n",
    "    for layerNum in range(numHiddenLayers+1):\n",
    "        if layerNum > 1:\n",
    "            regularizers = regularizers + tf.nn.l2_loss(weights['h' + str(layerNum)]) + tf.nn.l2_loss(biases['h' + str(layerNum)])\n",
    "\n",
    "    regularizers = regularizers + tf.nn.l2_loss(weights['out']) + tf.nn.l2_loss(biases['out'])\n",
    "    return regularizers\n",
    "\n",
    "def generateLossCalc(weights, biases, numHiddenLayers, trainingNetwork, trainingLabels, regularizationRate):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=trainingNetwork, labels=trainingLabels))\n",
    "    regularizers = generateRegularizers(weights, biases, numHiddenLayers)\n",
    "    loss += regularizationRate * regularizers\n",
    "    return loss\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(None, X_train.shape[1]))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(None, y_train.shape[1]))\n",
    "    tf_valid_dataset = tf.constant(X_valid.values)\n",
    "    tf_valid_labels = tf.constant(y_valid)\n",
    "\n",
    "    numHiddenLayers = _hiddenLayers.__len__()\n",
    "    weights = generateWeights(_hiddenLayers, _numInputs, _numLabels)\n",
    "    biases = generateBiases(_hiddenLayers, _numLabels)\n",
    "    trainingNetwork = multilayerNetwork(tf_train_dataset, weights, biases, numHiddenLayers, True, _dropoutKeepRate)\n",
    "    loss = generateLossCalc(weights, biases, numHiddenLayers, trainingNetwork, tf_train_labels, _regularizationRate)\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    learning_rate = tf.train.exponential_decay(_startLearningRate, global_step, _decaySteps, _learningDecayRate)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "\n",
    "    train_prediction = tf.nn.softmax(multilayerNetwork(tf_train_dataset, weights, biases, numHiddenLayers, True, _dropoutKeepRate))\n",
    "    valid_prediction = tf.nn.softmax(multilayerNetwork(tf_valid_dataset, weights, biases, numHiddenLayers, False, _dropoutKeepRate))\n",
    "    #test_prediction = tf.nn.softmax(multilayerNetwork(tf_test_dataset, weights, biases, numHiddenLayers, False, _dropoutKeepRate))\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(_numSteps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (np.random.randint(1, _trainSubset) * _batchSize) % (X_train.shape[0] - _batchSize)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = X_train.values[offset:(offset + _batchSize), :]\n",
    "        batch_labels = y_train[offset:(offset + _batchSize), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run(\n",
    "            [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        \n",
    "#         valid_data = X_valid.values\n",
    "#         valid_labels = y_valid\n",
    "        \n",
    "#         feed_dict = {\n",
    "#             tf_train_dataset: valid_data,\n",
    "#             tf_train_labels: valid_labels\n",
    "#         }\n",
    "        \n",
    "#         valid_l, valid_predictions = session.run([loss, train_prediction], feed_dict=feed_dict)\n",
    "\n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step\", step, \":\", l)\n",
    "            print(\"Minibatch accuracy: %.4f\" % accuracy(predictions, batch_labels).eval())\n",
    "            print(\"Valid accuracy: %.4f\" % accuracy(valid_predictions, valid_labels).eval())            \n",
    "            #print \"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels)\n",
    "\n",
    "#     print \"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 179 entries, 820 to 766\n",
      "Data columns (total 16 columns):\n",
      "Pclass         179 non-null int64\n",
      "Sex            179 non-null int64\n",
      "Age            179 non-null float64\n",
      "SibSp          179 non-null int64\n",
      "Parch          179 non-null int64\n",
      "Fare           179 non-null float64\n",
      "Cabin          179 non-null int64\n",
      "Embarked       179 non-null int64\n",
      "UnknownAge     179 non-null int64\n",
      "Baby           179 non-null int64\n",
      "Child          179 non-null int64\n",
      "Young          179 non-null int64\n",
      "FamilySize     179 non-null int64\n",
      "Alone          179 non-null int64\n",
      "Title          179 non-null int64\n",
      "TicketGroup    179 non-null float64\n",
      "dtypes: float64(3), int64(13)\n",
      "memory usage: 23.8 KB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
